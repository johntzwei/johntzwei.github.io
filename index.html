<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Hi, this is Nelson. Please DELETE the <script> block below (L6-L13)
          if you use this HTML, otherwise my analytics will track your page. -->
        <title>Johnny Tian-Zheng Wei | 魏天正</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="http://johntzwei.github.io" />
	    <meta property="og:title" content="Johnny Tian-Zheng Wei | 魏天正" />
	    <meta property="og:image" content="pic" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Johnny Tian-Zheng W">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="shortcut icon" type="image/png" href="favicon.ico"/>

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Johnny Tian-Zheng Wei | 魏天正</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 col-md-6 order-0 order-xs-0 order-sm-0 order-md-1 order-lg-1">
                    <div class="card mb-3">
			    <script>
				    var sites = [
					"pdfs/a_negative_result.txt",
					"pdfs/A_calculus_of_loss.pdf"
				    ];

				    function randomSite() {
					var i = parseInt(Math.random() * sites.length);
					location.href = sites[i];
				    }
				</script>
                        <a href="#" onclick="randomSite();"><img class="card-img-top" src="pic.jpg" alt="Johnny Tian-Zheng Wei"></a>
                        <div class="card-body">
                            <h5 class="card-title">
                                <b>Johnny Tian-Zheng Wei</b>
                            </h5>
                            <p class="card-text">
                                PhD Student
                                </br>
                                Computer Science Department
                                </br>
                                University of Southern California
                                </br>
                                </br>
                                Office: PHE 101
                                </br>
                                Pronouns: he/him
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-6 order-1 order-xs-1 order-sm-1 order-md-0 order-lg-0">
                    <p>
                        Hi! I am a PhD student (since fall 2019) focusing on natural language processing and machine learning at the <a href="https://www.usc.edu/"
                        target="_blank">University of Southern California</a>, where I am advised by <a href="https://robinjia.github.io/"
                        target="_blank">Robin Jia</a>. My current interest is in adaptive data collection. Previously, I earned a B.S. in Mathematics at the <a href="https://www.umass.edu/"
                        target="_blank">University of Massachusetts Amherst</a>. When there are slow weeks at school, I can be found lifting myself at the USC Parkside calisthenic park or riding my bikes to places within driving distance. Oh yeah, I also try to read different books.
                    </p>

                    <p>
                        If you would like to get in touch, feel free to email me! I am currently looking for an internship for the summer of 2022.
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <p>
                        Email: jtwei [<a href="https://en.wikipedia.org/wiki/At_sign" target="_blank">strudel</a>] usc.edu
                    </p>
                    <p>
                        Links:
                        [<a href="https://twitter.com/johntzwei" target="_blank">Twitter</a>] [<a href="https://github.com/johntzwei" target="_blank">Github</a>] [<a href="https://scholar.google.com/citations?user=TVFpiukAAAAJ" target="_blank">Google Scholar</a>]
                    </p>
                </div>
            </div>
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Selected publications</h2>
                    A full list of my publications can be found on <a href="https://scholar.google.com/citations?user=TVFpiukAAAAJ" target="_blank">Google Scholar</a>.
		    <br>
                    <ul class="pl">
                        <li>
                            <a href="https://aclanthology.org/2021.acl-long.533.pdf" target="_blank">
                                <b>The statistical advantage of automatic NLG metrics at the system level</b>
                            </a>
                            <br/>
                            <b>Johnny Tian-Zheng Wei</b>
                            and <a href="https://robinjia.github.io/" target="_blank">Robin Jia</a>.
                            <br/>
                                <b>ACL</b></a> 2021.
                            <br/>
                            [<a href="#" onclick="$('#statistical_advantage_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://github.com/johntzwei/metric-statistical-advantage" target="_blank">github</a>]
                            [<a href="https://aclanthology.org/2021.acl-long.533.bib" target="_blank">bib</a>]
                            <div id="statistical_advantage_abstract" class="abstract" style="display:none;">
                                <p>
                                    Estimating the expected output quality of generation systems is central to NLG. This paper qualifies the notion that automatic metrics are not as good as humans in estimating system-level quality. Statistically, humans are unbiased, high variance estimators, while metrics are biased, low variance estimators. We compare these estimators by their error in pairwise prediction (which generation system is better?) using the bootstrap. Measuring this error is complicated: predictions are evaluated against noisy, human predicted labels instead of the ground truth, and metric predictions fluctuate based on the test sets they were calculated on. By applying a bias-variance-noise decomposition, we adjust this error to a noise-free, infinite test set setting. Our analysis compares the adjusted error of metrics to humans and a derived, perfect segment-level annotator, both of which are unbiased estimators dependent on the number of judgments collected. In MT, we identify two settings where metrics outperform humans due to a statistical advantage in variance: when the number of human judgments used is small, and when the quality difference between compared systems is small.
                                </p>
                            </div>
                        </li>
		        <br/>
		    	<li>
                            <a href="https://aclanthology.org/2020.wmt-1.77.pdf" target="_blank">
                                <b>Results of the WMT20 Metrics Shared Task</b>
                            </a>
                            <br/>
			    <a href="https://aclanthology.org/people/n/nitika-mathur/" target="_blank">Nitika Mathur</a>,
                            <b>Johnny Tian-Zheng Wei</b>,
			    <a href="https://research.google/people/MarkusFreitag/" target="_blank">Markus Freitag</a>,
			    <a href="https://aclanthology.org/people/q/qingsong-ma/" target="_blank">Qingsong Ma</a>,
			    and <a href="https://ufal.mff.cuni.cz/ondrej-bojar" target="_blank">Ondřej Bojar</a>.
                            <br/>
                                <b>WMT</b></a> 2020.
                            <br/>
                            [<a href="#" onclick="$('#wmt2020_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://aclanthology.org/2020.wmt-1.77.bib" target="_blank">bib</a>]
                            <div id="wmt2020_abstract" class="abstract" style="display:none;">
                                <p>
                                    This paper presents the results of the WMT20 Metrics Shared Task. Participants were asked to score the outputs of the translation systems competing in the WMT20 News Translation Task with automatic metrics. Ten research groups submitted 27 metrics, four of which are reference-less “metrics”. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems. Finally, we investigate whether we can use automatic metrics to flag incorrect human ratings.
                                </p>
                            </div>
                        </li>
                        <br>
                        <li>
                            <a href="https://aclanthology.org/W19-5302.pdf" target="_blank">
                                <b>Results of the WMT19 Metrics Shared Task: Segment-Level and Strong MT Systems Pose Big Challenges</b>
                            </a>
                            <br/>
			    <a href="https://aclanthology.org/people/q/qingsong-ma/" target="_blank">Qingsong Ma</a>,
			    <b>Johnny Tian-Zheng Wei</b>,
			    <a href="https://ufal.mff.cuni.cz/ondrej-bojar" target="_blank">Ondřej Bojar</a>,
			    and <a href="https://www.scss.tcd.ie/~ygraham/" target="_blank">Yvette Graham</a>.
                            <br/>
                                <b>WMT</b></a> 2019.
                            <br/>
                            [<a href="#" onclick="$('#wmt2019_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://aclanthology.org/W19-5302.bib" target="_blank">bib</a>]
                            <div id="wmt2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    This paper presents the results of the WMT19 Metrics Shared Task. Participants were asked to score the outputs of the translations systems competing in the WMT19 News Translation Task with automatic metrics. 13 research groups submitted 24 metrics, 10 of which are reference-less “metrics” and constitute submissions to the joint task with WMT19 Quality Estimation Task, “QE as a Metric”. In addition, we computed 11 baseline metrics, with 8 commonly applied baselines (BLEU, SentBLEU, NIST, WER, PER, TER, CDER, and chrF) and 3 reimplementations (chrF+, sacreBLEU-BLEU, and sacreBLEU-chrF). Metrics were evaluated on the system level, how well a given metric correlates with the WMT19 official manual ranking, and segment level, how well the metric correlates with human judgements of segment quality. This year, we use direct assessment (DA) as our only form of manual evaluation.
                                </p>
                            </div>
                        </li>
                        <br>
                        <li>
                            <a href="https://aclanthology.org/W19-2310.pdf" target="_blank">
                                <b>Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings</b>
                            </a>
                            <br/>
			    <a href="https://www-scf.usc.edu/~sarikgha/" target="_blank">Sarik Ghazarian</a>,
			    <b>Johnny Tian-Zheng Wei</b>,
			    <a href="https://www.isi.edu/people/galstyan/about" target="_blank">Aram Galstyan</a>,
			    and <a href="https://vnpeng.net/" target="_blank">Nanyun Peng</a>.
                            <br/>
				<i>NeuralGen</i> @ <b>NAACL</b></a> 2019.
                            <br/>
                            [<a href="#" onclick="$('#contextual_aem_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://aclanthology.org/W19-2310.bib" target="_blank">bib</a>]
                            <div id="contextual_aem_abstract" class="abstract" style="display:none;">
                                <p>
                                    Despite advances in open-domain dialogue systems, automatic evaluation of such systems is still a challenging problem. Traditional reference-based metrics such as BLEU are ineffective because there could be many valid responses for a given context that share no common words with reference responses. A recent work proposed Referenced metric and Unreferenced metric Blended Evaluation Routine (RUBER) to combine a learning-based metric, which predicts relatedness between a generated response and a given query, with reference-based metric; it showed high correlation with human judgments. In this paper, we explore using contextualized word embeddings to compute more accurate relatedness scores, thus better evaluation metrics. Experiments show that our evaluation metrics outperform RUBER, which is trained on static embeddings.
                                </p>
                            </div>
                        </li>
			<br>
                        <li>
                            <a href="https://aclanthology.org/P18-1131.pdf" target="_blank">
                                <b>Twitter Universal Dependency Parsing for African-American and Mainstream American English</b>
                            </a>
                            <br/>
			    <a href="https://sblodgett.github.io/" target="_blank">Su Lin Blodgett</a>,
			    <b>Johnny Tian-Zheng Wei</b>,
			    and <a href="https://brenocon.com/" target="_blank">Brendan O'Connor</a>.
                            <br/>
				<b>ACL</b></a> 2018.
                            <br/>
                            [<a href="#" onclick="$('#aae_dependencies_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://aclanthology.org/P18-1131.bib" target="_blank">bib</a>]
                            <div id="aae_dependencies_abstract" class="abstract" style="display:none;">
                                <p>
                                    Due to the presence of both Twitter-specific conventions and non-standard and dialectal language, Twitter presents a significant parsing challenge to current dependency parsing tools. We broaden English dependency parsing to handle social media English, particularly social media African-American English (AAE), by developing and annotating a new dataset of 500 tweets, 250 of which are in AAE, within the Universal Dependencies 2.0 framework. We describe our standards for handling Twitter- and AAE-specific features and evaluate a variety of cross-domain strategies for improving parsing with no, or very little, in-domain labeled data, including a new data synthesis approach. We analyze these methods’ impact on performance disparities between AAE and Mainstream American English tweets, and assess parsing accuracy for specific AAE lexical and syntactic features. Our annotated data and a parsing model are available at: http://slanglab.cs.umass.edu/TwitterAAE/.
                                </p>
                            </div>
                        </li>
			<br>
                        <li>
                            <a href="https://aclanthology.org/W17-4408.pdf" target="_blank">
                                <b>A Dataset and Classifier for Recognizing Social Media English</b>
                            </a>
                            <br/>
			    <a href="https://sblodgett.github.io/" target="_blank">Su Lin Blodgett</a>,
			    <b>Johnny Tian-Zheng Wei</b>,
			    and <a href="https://brenocon.com/" target="_blank">Brendan O'Connor</a>.
                            <br/>
				<i> WNUT </i> @ <b>ACL</b></a> 2017. <b>Best paper award (WNUT)</b>.
                            <br/>
                            [<a href="#" onclick="$('#aae_langid_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://aclanthology.org/W17-4408.bib" target="_blank">bib</a>]
                            <div id="aae_langid_abstract" class="abstract" style="display:none;">
                                <p>
                                    While language identification works well on standard texts, it performs much worse on social media language, in particular dialectal language—even for English. First, to support work on English language identification, we contribute a new dataset of tweets annotated for English versus non-English, with attention to ambiguity, code-switching, and automatic generation issues. It is randomly sampled from all public messages, avoiding biases towards pre-existing language classifiers. Second, we find that a demographic language model—which identifies messages with language similar to that used by several U.S. ethnic populations on Twitter—can be used to improve English language identification performance when combined with a traditional supervised language identifier. It increases recall with almost no loss of precision, including, surprisingly, for English messages written by non-U.S. authors. Our dataset and identifier ensemble are available online.
                                </p>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Rejections</h2>
                    <ul>
                        <li>
                            NSF GRFP application (yes, the sequel, materials below). April, 2021.
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/1907.13362">On conducting better validation studies of automatic metrics in natural language generation evaluation.</a> <b>Johnny Tian-Zheng Wei</b>. Rejected from <i>NeuralGen</i> @ <b>NAACL</b> 2019. April, 2019.
                        </li>
                        <li>
                            NSF GRFP application (materials below). October, 2018
                        </li>
                        <li>
                            PhD applications to UW, Stanford, CMU, Cornell, NYU, JHU (in the order it hurts, materials below). January, 2019.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Writing</h2>
                    I have written a few tutorial pieces and application essays; I hope it may be useful to some people. More articles to come!
                    <ul>
			<li>
			    <a href="https://drive.google.com/file/d/1Y5pipzPYt4YSZzRAng2X8KllH166q0Ju/view?usp=sharing">A tale of bias and variance.</a> July, 2021.
                        <li>
                            NSF GRFP application materials. [ <a href="">personal statement</a> | <a href="pdfs/NSF_GRFP_Materials___Research_Proposal___Round_2 (10).pdf">research proposal</a> ] April, 2021.
                        </li>
                        <li>
                            Undergraduate thesis. [ <a href="pdfs/ug_thesis.pdf">Grammaticality in neural natural language generation.</a> ] May 2019.
                        </li>
                        <li>
                            Personal statement for PhD applications. [ Remarks | <a href="pdfs/uw_personal_statement.pdf">UW</a> ] December, 2018.
                        </li>
                        <li>
                            NSF GRFP application materials. [ <a href="pdfs/NSF_GRFP_Personal_Statement_final.pdf">personal statement</a> | <a href="pdfs/NSF_GRFP_Research_Proposal_final.pdf">research proposal</a> ] October, 2018.
                        </li>
                        <li>
                            <a href="pdfs/primer_syntax.pdf">A primer on syntax and context-free grammars.</a> May, 2018.
                        </li>
                        <li>
                            <a href="pdfs/unmeasurable_proof.pdf">My (detailed) proof of the existence of a standard unmeasurable set.</a> March, 2018.
                        </li>
                        <li>
                            <a href="pdfs/csli_short_answer.pdf">CSLI REU 2018 application materials.</a> February, 2017.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
			<li>
			    If you find yourself fixated on unhappy or unpleasant thoughts, you may benefit from therapy. I think resolving emotional difficulties need dedicated time and effort, and therapy is a constructive way to accomplish this. If you are a USC student, we have excellent resources (book an appointment on <a href="https://usc.edu/myshr">MySHR</a> or call <a href="tel:+1213-740-9355">(213) 740-9355</a>). If you are a student at an university in the US, check in with your health services to see if therapy and counseling services are offered - more may be available than you think! 
			</li>
			<li>
                            I recommend <a href="https://www.gatesnotes.com/Energy/My-new-climate-book-is-finally-here"
                            target="_blank">How to Avoid a Climate Disaster</a> for everyone, especially if you're an undergraduate or younger.
                        </li>
			<li>
                            I recommend <a href="https://www.penguinrandomhouse.com/books/348402/buddhism-without-beliefs-by-stephen-batchelor/"
                            target="_blank">Buddhism Without Beliefs: A Contemporary Guide to Awakening</a> for a patient reader; the book might offer an interesting insight or two. As an alternative, <a href="https://www.nytimes.com/2021/08/11/books/review-four-thousand-weeks-time-management-oliver-burkeman.html"
                            target="_blank">Four Thousand Weeks: Time Management for Mortals</a> can be a better read - lookout for the Buddhist themes throughout the book! 
                        </li>
			<li>
                            This webpage was adapted from <a href="https://nelsonliu.me"
                            target="_blank">Nelson's</a>. Thanks!
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                    </div>
                    <div class="col-6 col-md text-right">
                        <a href="https://cl.usc.edu/" class="image-link">
                            <img src="usc-nlp.png" alt="USC NLP logo." height="75">
                        </a>
                        <a href="https://www.usc.edu/" class="image-link">
                            <img src="usc-logo.png" alt="USC logo." height="75">
                        </a>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
